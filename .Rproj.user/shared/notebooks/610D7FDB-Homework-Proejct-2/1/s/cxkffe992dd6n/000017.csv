"0","# Initialize an empty dataframe to store vocabulary sizes"
"0","vocabulary_df <- data.frame(artist = character(), vocabulary_size = numeric())"
"0",""
"0","# Loop through each artist in the tokenized words list"
"0","for (artist in names(tokenized_words_list)) {"
"0","  # Get tokenized words for the current artist"
"0","  tokenized_words <- tokenized_words_list[[artist]]"
"0","  "
"0","  # Calculate vocabulary size (number of unique words)"
"0","  vocabulary_size <- length(unique(tokenized_words))"
"0","  "
"0","  # Add artist and vocabulary size to the dataframe"
"0","  vocabulary_df <- rbind(vocabulary_df, data.frame(artist = artist, vocabulary_size = vocabulary_size))"
"0","}"
"0",""
"0","# Sort the dataframe by vocabulary size"
"0","vocabulary_df <- vocabulary_df[order(vocabulary_df$vocabulary_size, decreasing = TRUE), ]"
"0",""
"0","# Print the dataframe to see which artists have the biggest and smallest vocabularies"
"0","head(vocabulary_df)"
